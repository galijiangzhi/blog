---
sidebar: auto
collapsable: true
---
# ResNet
## ResNet论文

[ResNet论文官方链接(点击查看)](https://arxiv.org/pdf/1512.03385)

[ResNet论文备用链接(点击查看)](http://www.apache2.sanyueyu.top/blog/ai/image_classification/resnet/resnet.pdf)

下面中文论文中有些图片分辨率太低了，图片方面可以参考上面备用链接里的图片

[GoogLeNet_v1论文中文pdf链接(点击查看)（本人翻译能力和手段有限，可以看看别人写的）](http://www.apache2.sanyueyu.top/blog/ai/image_classification/resnet/resnetcn.pdf)

ResNet团队表示，深度很大的网络通常难以训练，团队提出了残差学习框架，以便训练更深的网络。<br>

ResNet的网络深度高达152层，相比vgg网络深度增加了8倍，但是模型复杂度却仍然比较低。该网络在ImageNet测试集上达到了3.57的错误率。这个错误率已经超过了人眼的识别水平。<br>

在2015年，ResNet在ImageNet Classification，ImageNet Detection，ImageNet Localization，COCO Detection，COCO Segmentation这五个比赛中，包揽了冠军的同时，且大幅度领先第二名，后来ResNet论文被CVPR（计算机视觉与模式识别领域的顶级国际会议）评为2016年最佳论文。

## ResNet介绍
### 网络退化现象

在摘要部分，团队提到了一个网络退化现象：在传统网络的训练中，过高的深度会导致更高的误差，这一点在他们的实验中得到了充分的验证，这里我们用一张实验的图片就可以观察到网络退化现象:
![](./1.png)
左侧为训练集上的损失，右侧为测试集上的损失，可以观察到，在传统网络中，过度增加网络的深度会导致更高的误差，这并不是过拟合导致的，同时也不是由于梯度消失导致的，我们可以看到不管是20层网络还是56层网络的梯度还是在下降的，但是56层网络的效果就是不如20层好。

### 网络退化现象解决办法

首先，团队提出了一个观点，假设我们有一个网络模型，现在我们在这个模型的基础上加一些层产生一个新的模型，新模型是老模型+增加的层，按道理来说，新模型的误差应该比老模型更好才对（相当于给老模型进行了更细致的调整），但是实验结果表明事实并非如此。为了能让新模型的误差比老模型小，团队提出了一个结构，就是下图这个结构：
![](./2.png)
我们可以这样理解这个结构：该结构的**输出** = **该结构的输入** + **残差（也就是对输入的优化部分）**。这样就保证了新模型的效果一定比老模型好，这就是残差网络。

### 为什么使用残差会使性能变好
    
这个问题没有绝对的答案，但是有一些可以用于参考的说法，这里我列举一些我在学习的时候听到的说法：

**1**，残差网络可以防止梯度小时，因为“捷径连接”的梯度是1，可以保证梯度不会消失。<br>
**2**，残差结构类似于relu函数，relu函数在输入大于0的时候会映射一个值，小于0的时候会映射到0，这可以保证映射的结果不会是负的，同样使用残差模型的时候，残差经过优化至少可以保证模型不会向坏的方向发展。<br>
**3**,残差神经网络可以拟合恒等映射，有时候什么都不做比乱作要好。传统神经网络很难进行恒等映射。<br>
**4**,残差网络增加了相邻像素梯度的相关性（截至2024.6.19 这个论文我还没看，具体的理论实现有待学习。[点击此处查看论文](https://arxiv.org/abs/1702.08591)/[备用地址](http://www.apache2.sanyueyu.top/blog/ai/image_classification/resnet/4.pdf)）<br>
**5**，残差网络相当于集合浅层网络的集成，我们可以把残差网络像下面这样展开：
![](./3.png)
残差结构可以把模块并连起来，相比于传统的串联结构（比如vgg），并联结构中少数模块出问题不会对模型性能产生很大影响。串联结构就不一样，只要有一个模块出现问题，整体效果就会受到很大影响。（截至2024.6.19 这个论文我还没看，具体的理论实现有待学习。[点击此处查看论文](https://arxiv.org/abs/1605.06431)/[备用地址](http://www.apache2.sanyueyu.top/blog/ai/image_classification/resnet/5.pdf)）

